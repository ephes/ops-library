#!/usr/bin/env bash
# Managed by Ansible (openclaw_deploy weeknotes-md skill). Do not edit on the host.
# weeknotes-md skill handler — implements /todo add, /todo list, /note add, reminder, snooze, hello
set -euo pipefail

# --- Configuration (templated by Ansible at deploy time) ---
WEEKNOTES_DIR="{{ openclaw_weeknotes_container_dir }}"
WEEKNOTES_BACKEND="{{ openclaw_weeknotes_backend }}"
SNAPSHOTS_DIR="${WEEKNOTES_DIR}/.snapshots"
OPS_LOG="${WEEKNOTES_DIR}/.ops-log.jsonl"
LOCK_TIMEOUT={{ openclaw_weeknotes_lock_timeout }}
MAX_PAYLOAD={{ openclaw_weeknotes_max_payload_length }}
SNAPSHOT_MAX_COUNT={{ openclaw_weeknotes_snapshot_max_count }}
SNAPSHOT_MAX_DAYS={{ openclaw_weeknotes_snapshot_max_days }}

# --- Known sections (used for validation) ---
KNOWN_SECTIONS=("Todos" "Journal")

# --- Rate-limit configuration (templated by Ansible) ---
RATE_LIMIT_WRITES={{ openclaw_weeknotes_rate_limit_writes }}
RATE_LIMIT_WINDOW_SECS={{ openclaw_weeknotes_rate_limit_window_secs }}

# --- S3 backend configuration (injected via container env) ---
S3_ENDPOINT="${OPENCLAW_WEEKNOTES_S3_ENDPOINT:-}"
S3_REGION="${OPENCLAW_WEEKNOTES_S3_REGION:-us-east-1}"
S3_BUCKET="${OPENCLAW_WEEKNOTES_S3_BUCKET:-}"
S3_PREFIX="${OPENCLAW_WEEKNOTES_S3_PREFIX:-}"
S3_ACCESS_KEY="${OPENCLAW_WEEKNOTES_S3_ACCESS_KEY:-}"
S3_SECRET_KEY="${OPENCLAW_WEEKNOTES_S3_SECRET_KEY:-}"
S3_NOTE_KEY_FORMAT="${OPENCLAW_WEEKNOTES_S3_NOTE_KEY_FORMAT:-%Y-%m-%d.md}"
S3_TODO_LIST_MODE="${OPENCLAW_WEEKNOTES_S3_TODO_LIST_MODE:-current_note}"
S3_TODO_LIST_KEY_REGEX="${OPENCLAW_WEEKNOTES_S3_TODO_LIST_KEY_REGEX:-}"
if [[ -z "$S3_TODO_LIST_KEY_REGEX" ]]; then
  S3_TODO_LIST_KEY_REGEX='^[0-9]{4}-[0-9]{2}-[0-9]{2}\.md$'
fi
TODO_CACHE_DIR="${WEEKNOTES_DIR}/.todo-cache"
TODO_CACHE_INDEX="${TODO_CACHE_DIR}/index.tsv"
TODO_CACHE_LOCK="${WEEKNOTES_DIR}/.todo-cache.lock"
TODO_CACHE_LAST_SYNC="${TODO_CACHE_DIR}/last_sync.epoch"
TODO_CACHE_ALL_TASKS="${TODO_CACHE_DIR}/all_open_tasks.txt"
TODO_CACHE_LOG="${TODO_CACHE_DIR}/refresh.log"
TODO_CACHE_DIRTY="${TODO_CACHE_DIR}/dirty.epoch"
TODO_CACHE_REFRESH_SECS="${OPENCLAW_WEEKNOTES_S3_TODO_CACHE_REFRESH_SECS:-120}"
S3_MC_ALIAS="${OPENCLAW_WEEKNOTES_S3_MC_ALIAS:-weeknotes}"
S3_MC_BIN="${OPENCLAW_WEEKNOTES_S3_MC_BIN:-/usr/local/bin/mc}"
S3_MC_CONFIG_DIR="${WEEKNOTES_DIR}/.mc"

# --- Helpers ---

json_escape() {
  local s="$1"
  s="${s//\\/\\\\}"
  s="${s//\"/\\\"}"
  s="${s//$'\n'/\\n}"
  s="${s//$'\t'/\\t}"
  s="${s//$'\r'/\\r}"
  printf '%s' "$s"
}

sanitize_name() {
  printf '%s' "$1" | sed -E 's#[^A-Za-z0-9._-]#_#g'
}

count_args() {
  local count=0
  local _
  for _ in "$@"; do
    count=$((count + 1))
  done
  printf '%d' "$count"
}

s3_enabled() {
  [[ "$WEEKNOTES_BACKEND" == "s3" ]]
}

check_rate_limit() {
  local sender="${1:-unknown}"
  [[ "$RATE_LIMIT_WRITES" -le 0 ]] && return 0
  [[ ! -f "$OPS_LOG" ]] && return 0

  local cutoff_epoch
  cutoff_epoch=$(( $(date +%s) - RATE_LIMIT_WINDOW_SECS ))

  local count=0
  local sender_escaped
  sender_escaped="$(json_escape "$sender")"

  while IFS= read -r line; do
    [[ -z "$line" ]] && continue
    [[ "$line" == *"\"sender\":\"${sender_escaped}\""* ]] || continue
    [[ "$line" == *'"status":"ok"'* ]] || continue

    local line_epoch="${line#*\"epoch\":}"
    line_epoch="${line_epoch%%[,\}]*}"
    [[ "$line_epoch" =~ ^[0-9]+$ ]] || continue

    (( line_epoch >= cutoff_epoch )) && count=$((count + 1))
  done < "$OPS_LOG"

  if (( count >= RATE_LIMIT_WRITES )); then
    printf 'ERROR: Rate limit exceeded — max %d writes per %d seconds' "$RATE_LIMIT_WRITES" "$RATE_LIMIT_WINDOW_SECS"
    return 1
  fi
  return 0
}

current_week_file() {
  date +"%G-W%V.md"
}

current_s3_note_key() {
  local note_name prefix
  note_name=$(date +"${S3_NOTE_KEY_FORMAT}")
  prefix="${S3_PREFIX#/}"
  prefix="${prefix%/}"
  if [[ -n "$prefix" ]]; then
    printf '%s/%s' "$prefix" "$note_name"
  else
    printf '%s' "$note_name"
  fi
}

current_note_id() {
  if s3_enabled; then
    current_s3_note_key
  else
    current_week_file
  fi
}

ensure_week_file() {
  local file="${WEEKNOTES_DIR}/$(current_week_file)"
  if [[ ! -f "$file" ]]; then
    local week_label
    week_label=$(date +"%G-W%V")
    printf '# Week %s\n\n## Todos\n\n## Journal\n' "$week_label" > "$file"
    chmod 0640 "$file"
  fi
  printf '%s' "$file"
}

create_default_daily_note_file() {
  local file="$1"
  local note_label
  note_label=$(date +"%Y-%m-%d")
  printf '# %s\n\n## Todos\n\n## Journal\n' "$note_label" > "$file"
  chmod 0640 "$file"
}

create_snapshot() {
  local file="$1"
  local ts
  ts=$(date -u +"%Y%m%dT%H%M%SZ")
  local snap="${SNAPSHOTS_DIR}/$(basename "$file").${ts}.bak"
  cp -- "$file" "$snap"
  chmod 0640 "$snap"
  printf '%s' "$snap"
}

snapshot_basename_for_key() {
  sanitize_name "$1"
}

create_snapshot_for_key() {
  local key="$1" source_file="$2"
  local ts base
  ts=$(date -u +"%Y%m%dT%H%M%SZ")
  base=$(snapshot_basename_for_key "$key")
  local snap="${SNAPSHOTS_DIR}/${base}.${ts}.bak"
  cp -- "$source_file" "$snap"
  chmod 0640 "$snap"
  printf '%s' "$snap"
}

log_op() {
  local op="$1" file="$2" section="$3" status="$4"
  local snapshot_path="${5:-}" error="${6:-}" sender="${7:-unknown}" meta="${8:-}"
  local ts epoch
  ts=$(date +"%Y-%m-%dT%H:%M:%S%z")
  epoch=$(date +%s)

  local json="{\"ts\":\"${ts}\",\"epoch\":${epoch},\"backend\":\"$(json_escape "$WEEKNOTES_BACKEND")\",\"op\":\"$(json_escape "$op")\",\"file\":\"$(json_escape "$file")\",\"section\":\"$(json_escape "$section")\",\"status\":\"$(json_escape "$status")\""
  [[ -n "$snapshot_path" ]] && json+=",\"snapshot_path\":\"$(json_escape "$snapshot_path")\""
  [[ -n "$error" ]] && json+=",\"error\":\"$(json_escape "$error")\""
  [[ -n "$meta" ]] && json+=",\"meta\":\"$(json_escape "$meta")\""
  json+=",\"sender\":\"$(json_escape "$sender")\"}"
  printf '%s\n' "$json" >> "$OPS_LOG"
}

validate_file() {
  local file="$1"

  if ! iconv -f UTF-8 -t UTF-8 "$file" > /dev/null 2>&1; then
    printf 'ERROR: File contains invalid UTF-8'
    return 1
  fi

  local s count
  for s in "${KNOWN_SECTIONS[@]}"; do
    count=$(grep -c "^## ${s}$" "$file" 2>/dev/null || true)
    count=${count:-0}
    if (( count > 1 )); then
      printf 'ERROR: Duplicate "## %s" markers found in file' "$s"
      return 1
    fi
  done
  return 0
}

append_to_section() {
  local file="$1" section="$2" entry="$3"

  local val_err
  if ! val_err=$(validate_file "$file"); then
    printf '%s' "$val_err"
    return 1
  fi

  if ! grep -q "^## ${section}$" "$file"; then
    printf '\n## %s\n' "$section" >> "$file"
    printf 'WARNING: Added missing "## %s" marker at EOF\n' "$section" >&2
  fi

  local section_line
  section_line=$(grep -n "^## ${section}$" "$file" | head -1 | cut -d: -f1)

  local total_lines
  total_lines=$(wc -l < "$file")
  local next_section_line=""
  if [[ "$section_line" -lt "$total_lines" ]]; then
    local relative
    relative=$(tail -n "+$((section_line + 1))" "$file" | grep -n "^## " | head -1 | cut -d: -f1)
    if [[ -n "$relative" ]]; then
      next_section_line=$((section_line + relative))
    fi
  fi

  local tmpfile
  tmpfile=$(mktemp "${file}.tmp.XXXXXX")

  if [[ -n "$next_section_line" ]]; then
    local insert_before=$((next_section_line))
    head -n "$((insert_before - 1))" "$file" > "$tmpfile"
    printf '%s\n' "$entry" >> "$tmpfile"
    tail -n "+${insert_before}" "$file" >> "$tmpfile"
  else
    cat "$file" > "$tmpfile"
    if [[ -s "$file" ]] && [[ "$(tail -c 1 "$file" | wc -l)" -eq 0 ]]; then
      printf '\n' >> "$tmpfile"
    fi
    printf '%s\n' "$entry" >> "$tmpfile"
  fi

  mv -- "$tmpfile" "$file"
  chmod 0640 "$file"
}

prune_snapshots() {
  local base_name="$1"
  local pattern="${base_name}.*Z.bak"

  find "$SNAPSHOTS_DIR" -name "$pattern" -mtime "+${SNAPSHOT_MAX_DAYS}" -type f -delete 2>/dev/null || true

  local count=0
  local snaps
  snaps=$(find "$SNAPSHOTS_DIR" -name "$pattern" -type f 2>/dev/null | sort -r)
  while IFS= read -r snap; do
    [[ -z "$snap" ]] && continue
    count=$((count + 1))
    if (( count > SNAPSHOT_MAX_COUNT )); then
      rm -f -- "$snap"
    fi
  done <<< "$snaps"
}

require_s3_config() {
  local missing=()
  [[ -z "$S3_ENDPOINT" ]] && missing+=("OPENCLAW_WEEKNOTES_S3_ENDPOINT")
  [[ -z "$S3_BUCKET" ]] && missing+=("OPENCLAW_WEEKNOTES_S3_BUCKET")
  [[ -z "$S3_ACCESS_KEY" ]] && missing+=("OPENCLAW_WEEKNOTES_S3_ACCESS_KEY")
  [[ -z "$S3_SECRET_KEY" ]] && missing+=("OPENCLAW_WEEKNOTES_S3_SECRET_KEY")

  if (( $(count_args "${missing[@]}") > 0 )); then
    printf 'ERROR: Missing S3 config: %s' "$(IFS=', '; printf '%s' "${missing[*]}")"
    return 1
  fi

  if [[ ! -x "$S3_MC_BIN" ]]; then
    printf 'ERROR: S3 client not executable at %s' "$S3_MC_BIN"
    return 1
  fi

  return 0
}

s3_mc() {
  "$S3_MC_BIN" --config-dir "$S3_MC_CONFIG_DIR" "$@"
}

s3_init_alias() {
  mkdir -p "$S3_MC_CONFIG_DIR"
  chmod 0700 "$S3_MC_CONFIG_DIR"
  s3_mc alias set "$S3_MC_ALIAS" "$S3_ENDPOINT" "$S3_ACCESS_KEY" "$S3_SECRET_KEY" > /dev/null 2>&1
}

s3_object_ref() {
  local key="$1"
  printf '%s/%s/%s' "$S3_MC_ALIAS" "$S3_BUCKET" "$key"
}

s3_download_to_file() {
  local key="$1" dest="$2"
  s3_mc cat "$(s3_object_ref "$key")" > "$dest" 2>/dev/null
}

s3_object_exists() {
  local key="$1"
  s3_mc stat "$(s3_object_ref "$key")" > /dev/null 2>&1
}

s3_upload_from_file() {
  local source_file="$1" key="$2"
  s3_mc cp --quiet "$source_file" "$(s3_object_ref "$key")" > /dev/null 2>&1
}

s3_stat_etag() {
  local key="$1"
  s3_mc stat --json "$(s3_object_ref "$key")" 2>/dev/null | sed -n 's/.*"etag":"\([^"]*\)".*/\1/p' | head -1
}

collect_open_todos_from_file() {
  local file="$1"
  local -n out_todos="$2"
  out_todos=()

  local in_todos=false
  local line
  while IFS= read -r line; do
    if [[ "$line" =~ ^##[[:space:]]Todo(s)?$ ]]; then
      in_todos=true
      continue
    fi
    if $in_todos && [[ "$line" =~ ^##[[:space:]] ]]; then
      break
    fi
    if $in_todos && [[ "$line" =~ ^-[[:space:]]\[[[:space:]]\] ]]; then
      out_todos+=("$line")
    fi
  done < "$file"
}

collect_open_tasks_from_file() {
  local file="$1"
  local -n out_todos="$2"
  out_todos=()

  local line
  while IFS= read -r line; do
    if [[ "$line" =~ ^-[[:space:]]\[[[:space:]]\] ]]; then
      out_todos+=("$line")
    fi
  done < "$file"
}

list_s3_note_keys_for_todo_list() {
  local listing_ref prefix ls_tmp line key etag base
  listing_ref="${S3_MC_ALIAS}/${S3_BUCKET}"
  prefix="${S3_PREFIX#/}"
  prefix="${prefix%/}"
  if [[ -n "$prefix" ]]; then
    listing_ref="${listing_ref}/${prefix}"
  fi

  ls_tmp=$(mktemp "${WEEKNOTES_DIR}/.s3-listing.XXXXXX")
  if ! s3_mc ls --recursive --json "$listing_ref" > "$ls_tmp" 2>/dev/null; then
    rm -f -- "$ls_tmp"
    return 1
  fi

  while IFS= read -r line; do
    [[ "$line" == *'"type":"file"'* ]] || continue
    key=$(printf '%s' "$line" | sed -n 's/.*"key":"\([^"]*\)".*/\1/p')
    etag=$(printf '%s' "$line" | sed -n 's/.*"etag":"\([^"]*\)".*/\1/p')
    [[ -z "$key" ]] && continue
    if [[ -n "$prefix" && "$key" != "${prefix}/"* ]]; then
      key="${prefix}/${key}"
    fi
    base="${key##*/}"
    if printf '%s\n' "$base" | grep -Eq "$S3_TODO_LIST_KEY_REGEX"; then
      printf '%s\t%s\n' "$key" "$etag"
    fi
  done < "$ls_tmp"

  rm -f -- "$ls_tmp"
  return 0
}

trim_todo_cache_log_if_needed() {
  [[ -f "$TODO_CACHE_LOG" ]] || return 0
  local bytes
  bytes=$(wc -c < "$TODO_CACHE_LOG" 2>/dev/null || printf '0')
  [[ "$bytes" =~ ^[0-9]+$ ]] || bytes=0
  if (( bytes > 102400 )); then
    local tmp
    tmp=$(mktemp "${TODO_CACHE_DIR}/refresh.log.tmp.XXXXXX")
    tail -c 51200 "$TODO_CACHE_LOG" > "$tmp" 2>/dev/null || true
    mv -- "$tmp" "$TODO_CACHE_LOG"
    chmod 0640 "$TODO_CACHE_LOG"
  fi
}

mark_todo_cache_dirty() {
  mkdir -p "$TODO_CACHE_DIR"
  local now tmp
  now=$(date +%s)
  tmp=$(mktemp "${TODO_CACHE_DIR}/dirty.tmp.XXXXXX")
  printf '%s\n' "$now" > "$tmp"
  mv -- "$tmp" "$TODO_CACHE_DIRTY"
  chmod 0640 "$TODO_CACHE_DIRTY"
}

cache_key_id() {
  local key="$1"
  printf '%s' "$key" | sha1sum | cut -d' ' -f1
}

cache_tasks_file_for_key() {
  local key="$1"
  local key_id
  key_id=$(cache_key_id "$key")
  printf '%s/%s.tasks' "$TODO_CACHE_DIR" "$key_id"
}

refresh_s3_todo_cache_for_daily_notes() {
  mkdir -p "$TODO_CACHE_DIR"

  (
    flock -w "$LOCK_TIMEOUT" 201 || return 1

    local now_epoch refresh_started_epoch last_sync=0
    now_epoch=$(date +%s)
    refresh_started_epoch="$now_epoch"
    if [[ -f "$TODO_CACHE_LAST_SYNC" ]]; then
      read -r last_sync < "$TODO_CACHE_LAST_SYNC" || true
      [[ "$last_sync" =~ ^[0-9]+$ ]] || last_sync=0
    fi
    if [[ -f "$TODO_CACHE_INDEX" ]] && (( now_epoch - last_sync < TODO_CACHE_REFRESH_SECS )); then
      return 0
    fi

    local tmp_index
    tmp_index=$(mktemp "${TODO_CACHE_DIR}/index.tmp.XXXXXX")
    local listing_tmp
    listing_tmp=$(mktemp "${TODO_CACHE_DIR}/listing.tmp.XXXXXX")
    if ! list_s3_note_keys_for_todo_list | sort > "$listing_tmp"; then
      rm -f -- "$listing_tmp" "$tmp_index"
      return 1
    fi

    local -A old_etag=()
    if [[ -f "$TODO_CACHE_INDEX" ]]; then
      local old_key old_value
      while IFS=$'\t' read -r old_key old_value; do
        [[ -z "$old_key" ]] && continue
        old_etag["$old_key"]="$old_value"
      done < "$TODO_CACHE_INDEX"
    fi

    local -A seen=()
    local key etag old_value task_file tmp_file refresh_failed
    while IFS=$'\t' read -r key etag; do
      [[ -z "$key" ]] && continue
      seen["$key"]=1
      old_value="${old_etag[$key]-}"
      task_file=$(cache_tasks_file_for_key "$key")
      refresh_failed=false

      if [[ ! -f "$task_file" || "$old_value" != "$etag" ]]; then
        tmp_file=$(mktemp "${WEEKNOTES_DIR}/.s3-cache-refresh.XXXXXX")
        if s3_download_to_file "$key" "$tmp_file"; then
          local file_todos=()
          collect_open_tasks_from_file "$tmp_file" file_todos
          : > "$task_file"
          local todo
          for todo in "${file_todos[@]}"; do
            printf '%s\n' "$todo" >> "$task_file"
          done
          chmod 0640 "$task_file"
        else
          refresh_failed=true
        fi
        rm -f -- "$tmp_file"
      fi

      if [[ "$refresh_failed" == "true" ]]; then
        if [[ -n "$old_value" && -f "$task_file" ]]; then
          printf '%s\t%s\n' "$key" "$old_value" >> "$tmp_index"
        fi
        continue
      fi

      printf '%s\t%s\n' "$key" "$etag" >> "$tmp_index"
    done < "$listing_tmp"
    rm -f -- "$listing_tmp"

    if [[ -f "$TODO_CACHE_INDEX" ]]; then
      local stale_key stale_file
      while IFS=$'\t' read -r stale_key _; do
        [[ -z "$stale_key" ]] && continue
        if [[ -z "${seen[$stale_key]+x}" ]]; then
          stale_file=$(cache_tasks_file_for_key "$stale_key")
          rm -f -- "$stale_file"
        fi
      done < "$TODO_CACHE_INDEX"
    fi

    local tmp_all
    tmp_all=$(mktemp "${TODO_CACHE_DIR}/all.tmp.XXXXXX")
    local out_key out_etag out_task_file
    while IFS=$'\t' read -r out_key out_etag; do
      [[ -z "$out_key" ]] && continue
      out_task_file=$(cache_tasks_file_for_key "$out_key")
      [[ -f "$out_task_file" ]] || continue
      cat -- "$out_task_file" >> "$tmp_all"
    done < "$tmp_index"

    mv -- "$tmp_index" "$TODO_CACHE_INDEX"
    chmod 0640 "$TODO_CACHE_INDEX"
    mv -- "$tmp_all" "$TODO_CACHE_ALL_TASKS"
    chmod 0640 "$TODO_CACHE_ALL_TASKS"
    printf '%s\n' "$now_epoch" > "$TODO_CACHE_LAST_SYNC"
    chmod 0640 "$TODO_CACHE_LAST_SYNC"

    local dirty_epoch=0
    if [[ -f "$TODO_CACHE_DIRTY" ]]; then
      read -r dirty_epoch < "$TODO_CACHE_DIRTY" || true
      [[ "$dirty_epoch" =~ ^[0-9]+$ ]] || dirty_epoch=0
    fi
    if (( dirty_epoch <= refresh_started_epoch )); then
      rm -f -- "$TODO_CACHE_DIRTY"
    fi
  ) 201>"${TODO_CACHE_LOCK}"
}

todo_cache_is_fresh() {
  [[ -f "$TODO_CACHE_INDEX" ]] || return 1
  [[ -f "$TODO_CACHE_ALL_TASKS" ]] || return 1

  local now_epoch last_sync=0
  now_epoch=$(date +%s)
  if [[ -f "$TODO_CACHE_LAST_SYNC" ]]; then
    read -r last_sync < "$TODO_CACHE_LAST_SYNC" || true
    [[ "$last_sync" =~ ^[0-9]+$ ]] || last_sync=0
  fi
  [[ -f "$TODO_CACHE_DIRTY" ]] && return 1
  (( now_epoch - last_sync < TODO_CACHE_REFRESH_SECS ))
}

collect_s3_open_tasks_from_daily_notes() {
  local -n out_todos="$1"
  out_todos=()

  if ! todo_cache_is_fresh; then
    if [[ -f "$TODO_CACHE_ALL_TASKS" && -f "$TODO_CACHE_INDEX" ]]; then
      trim_todo_cache_log_if_needed
      refresh_s3_todo_cache_for_daily_notes >> "$TODO_CACHE_LOG" 2>&1 &
    else
      if ! refresh_s3_todo_cache_for_daily_notes; then
        return 1
      fi
    fi
  fi

  local line
  if [[ -f "$TODO_CACHE_ALL_TASKS" ]]; then
    while IFS= read -r line; do
      [[ -z "$line" ]] && continue
      out_todos+=("$line")
    done < "$TODO_CACHE_ALL_TASKS"
  fi
}

# --- Argument parsing helpers ---

parse_priority() {
  local text="$*"
  if [[ "$text" == *"--p1"* ]]; then printf 'P1'
  elif [[ "$text" == *"--p3"* ]]; then printf 'P3'
  else printf 'P2'
  fi
}

parse_due() {
  local text="$*"
  if [[ "$text" =~ --due[[:space:]]+([0-9]{4}-[0-9]{2}-[0-9]{2}) ]]; then
    printf '%s' "${BASH_REMATCH[1]}"
  fi
}

parse_tags() {
  local text="$*"
  local tags=""
  local word
  for word in $text; do
    if [[ "$word" =~ ^#[a-zA-Z0-9_]+ ]]; then
      tags="${tags:+$tags }${word}"
    fi
  done
  printf '%s' "$tags"
}

clean_text() {
  local text="$*"
  text="${text//--p1/}"
  text="${text//--p2/}"
  text="${text//--p3/}"
  text=$(printf '%s' "$text" | sed -E 's/--due[[:space:]]+[0-9]{4}-[0-9]{2}-[0-9]{2}//')
  text=$(printf '%s' "$text" | sed -E 's/#[a-zA-Z0-9_]+//g')
  text=$(printf '%s' "$text" | sed -E 's/[[:space:]]+/ /g; s/^ //; s/ $//')
  printf '%s' "$text"
}

write_entry_local() {
  local op="$1" section="$2" entry="$3" success_prefix="$4"

  local file
  file=$(ensure_week_file)
  local basename_f
  basename_f=$(basename "$file")
  local snap
  snap=$(create_snapshot "$file")

  local result
  if result=$(append_to_section "$file" "$section" "$entry"); then
    log_op "$op" "$basename_f" "$section" "ok" "$snap" "" "${SENDER:-unknown}"
    prune_snapshots "$basename_f"
    printf '%s: %s' "$success_prefix" "$entry"
    return 0
  fi

  log_op "$op" "$basename_f" "$section" "error" "" "$result" "${SENDER:-unknown}"
  cp -- "$snap" "$file"
  printf '%s' "$result"
  return 1
}

write_entry_s3() {
  local op="$1" section="$2" entry="$3" success_prefix="$4"

  if ! require_s3_config; then
    return 1
  fi
  if ! s3_init_alias; then
    printf 'ERROR: Failed to initialize S3 client alias'
    return 1
  fi

  local key
  key=$(current_s3_note_key)
  local snapshot_base
  snapshot_base=$(snapshot_basename_for_key "$key")

  local tmp_current tmp_verify
  tmp_current=$(mktemp "${WEEKNOTES_DIR}/.s3-current.XXXXXX")
  tmp_verify=$(mktemp "${WEEKNOTES_DIR}/.s3-verify.XXXXXX")

  local pre_etag=""
  if s3_object_exists "$key"; then
    if ! s3_download_to_file "$key" "$tmp_current"; then
      log_op "$op" "$key" "$section" "error" "" "ERROR: Failed to read existing object from object store" "${SENDER:-unknown}" "key=${key}"
      rm -f -- "$tmp_current" "$tmp_verify"
      printf 'ERROR: Failed to read existing object from object store'
      return 1
    fi
    pre_etag="$(s3_stat_etag "$key")"
  else
    create_default_daily_note_file "$tmp_current"
  fi

  local snap
  snap=$(create_snapshot_for_key "$key" "$tmp_current")

  local result
  if ! result=$(append_to_section "$tmp_current" "$section" "$entry"); then
    log_op "$op" "$key" "$section" "error" "" "$result" "${SENDER:-unknown}" "pre_etag=${pre_etag};key=${key}"
    rm -f -- "$tmp_current" "$tmp_verify"
    printf '%s' "$result"
    return 1
  fi

  if ! s3_upload_from_file "$tmp_current" "$key"; then
    log_op "$op" "$key" "$section" "error" "" "ERROR: Failed to upload note to object store" "${SENDER:-unknown}" "pre_etag=${pre_etag};key=${key}"
    rm -f -- "$tmp_current" "$tmp_verify"
    printf 'ERROR: Failed to upload note to object store'
    return 1
  fi

  if ! s3_download_to_file "$key" "$tmp_verify"; then
    log_op "$op" "$key" "$section" "error" "" "ERROR: Failed to verify post-write object state" "${SENDER:-unknown}" "pre_etag=${pre_etag};key=${key}"
    rm -f -- "$tmp_current" "$tmp_verify"
    printf 'ERROR: Failed to verify post-write object state'
    return 1
  fi

  if ! cmp -s "$tmp_current" "$tmp_verify"; then
    local post_etag_conflict
    post_etag_conflict="$(s3_stat_etag "$key")"
    log_op "$op" "$key" "$section" "error" "" "ERROR: Write verification failed — concurrent edit suspected, retry" "${SENDER:-unknown}" "pre_etag=${pre_etag};post_etag=${post_etag_conflict};key=${key}"
    rm -f -- "$tmp_current" "$tmp_verify"
    printf 'ERROR: Write verification failed — concurrent edit suspected, retry'
    return 1
  fi

  local post_etag
  post_etag="$(s3_stat_etag "$key")"
  log_op "$op" "$key" "$section" "ok" "$snap" "" "${SENDER:-unknown}" "pre_etag=${pre_etag};post_etag=${post_etag};key=${key}"
  prune_snapshots "$snapshot_base"

  rm -f -- "$tmp_current" "$tmp_verify"
  printf '%s: %s' "$success_prefix" "$entry"
  return 0
}

# --- Commands ---

cmd_todo_add() {
  local text="$*"
  [[ -z "$text" ]] && { printf 'ERROR: Empty todo text'; exit 1; }
  [[ $(printf '%s' "$text" | wc -m) -gt $MAX_PAYLOAD ]] && { printf 'ERROR: Text exceeds %d characters' "$MAX_PAYLOAD"; exit 1; }

  local priority due tags clean
  priority=$(parse_priority "$text")
  due=$(parse_due "$text")
  tags=$(parse_tags "$text")
  clean=$(clean_text "$text")

  [[ -z "$clean" ]] && { printf 'ERROR: Empty todo text after parsing flags'; exit 1; }

  local entry="- [ ] [${priority}] ${clean}"
  [[ -n "$due" ]] && entry+=" @due:${due}"
  [[ -n "$tags" ]] && entry+=" ${tags}"

  local note_id lock_path
  note_id=$(current_note_id)
  lock_path="${WEEKNOTES_DIR}/$(sanitize_name "$note_id").lock"

  (
    flock -w "$LOCK_TIMEOUT" 200 || { printf 'ERROR: Lock timeout after %ds — retry later' "$LOCK_TIMEOUT"; exit 1; }

    if ! check_rate_limit "${SENDER:-unknown}"; then
      exit 1
    fi

    if s3_enabled; then
      write_entry_s3 "todo_add" "Todos" "$entry" "Added todo"
    else
      write_entry_local "todo_add" "Todos" "$entry" "Added todo"
    fi
  ) 200>"${lock_path}"

  if s3_enabled && [[ "$S3_TODO_LIST_MODE" == "daily_notes" ]]; then
    mark_todo_cache_dirty
    rm -f -- "$TODO_CACHE_LAST_SYNC"
  fi
}

cmd_todo_list() {
  local file tmp_file="" todos=()

  if s3_enabled; then
    if ! require_s3_config; then
      exit 1
    fi
    s3_init_alias || { printf 'ERROR: Failed to initialize S3 client alias'; exit 1; }

    if [[ "$S3_TODO_LIST_MODE" == "daily_notes" ]]; then
      collect_s3_open_tasks_from_daily_notes todos
    else
      local key
      key=$(current_s3_note_key)
      tmp_file=$(mktemp "${WEEKNOTES_DIR}/.s3-list.XXXXXX")
      if ! s3_object_exists "$key"; then
        rm -f -- "$tmp_file"
        printf 'No note file for current date.'
        exit 0
      fi
      if ! s3_download_to_file "$key" "$tmp_file"; then
        rm -f -- "$tmp_file"
        printf 'ERROR: Failed to read current note from object store.'
        exit 1
      fi
      file="$tmp_file"
      collect_open_todos_from_file "$file" todos
    fi
  else
    file="${WEEKNOTES_DIR}/$(current_week_file)"
    if [[ ! -f "$file" ]]; then
      printf 'No weeknotes file for current week.'
      exit 0
    fi
    collect_open_todos_from_file "$file" todos
  fi

  rm -f -- "$tmp_file"

  if (( $(count_args "${todos[@]}") == 0 )); then
    if s3_enabled && [[ "$S3_TODO_LIST_MODE" == "daily_notes" ]]; then
      printf 'No open todos in matching daily notes.'
    else
      printf 'No open todos for this week.'
    fi
    exit 0
  fi

  local todo
  for todo in "${todos[@]}"; do
    printf '%s\n' "$todo"
  done
}

cmd_note_add() {
  local text="$*"
  [[ -z "$text" ]] && { printf 'ERROR: Empty note text'; exit 1; }
  [[ $(printf '%s' "$text" | wc -m) -gt $MAX_PAYLOAD ]] && { printf 'ERROR: Text exceeds %d characters' "$MAX_PAYLOAD"; exit 1; }

  local ts
  ts=$(date +"%Y-%m-%d %H:%M")
  local entry="- ${ts} ${text}"

  local note_id lock_path
  note_id=$(current_note_id)
  lock_path="${WEEKNOTES_DIR}/$(sanitize_name "$note_id").lock"

  (
    flock -w "$LOCK_TIMEOUT" 200 || { printf 'ERROR: Lock timeout after %ds — retry later' "$LOCK_TIMEOUT"; exit 1; }

    if ! check_rate_limit "${SENDER:-unknown}"; then
      exit 1
    fi

    if s3_enabled; then
      write_entry_s3 "note_add" "Journal" "$entry" "Added note"
    else
      write_entry_local "note_add" "Journal" "$entry" "Added note"
    fi
  ) 200>"${lock_path}"
}

cmd_snooze() {
  local today
  today=$(date +"%Y-%m-%d")
  printf '%s\n' "$today" > "${WEEKNOTES_DIR}/.snooze"
  printf 'Reminder snoozed for today (%s).' "$today"
}

cmd_reminder() {
  local file tmp_file="" todos=()

  local snooze_file="${WEEKNOTES_DIR}/.snooze"
  if [[ -f "$snooze_file" ]]; then
    local snooze_date
    snooze_date=$(head -1 "$snooze_file" 2>/dev/null || true)
    if [[ "$snooze_date" == "$(date +"%Y-%m-%d")" ]]; then
      exit 0
    fi
  fi

  if s3_enabled; then
    require_s3_config || exit 0
    s3_init_alias || exit 0

    if [[ "$S3_TODO_LIST_MODE" == "daily_notes" ]]; then
      collect_s3_open_tasks_from_daily_notes todos
    else
      local key
      key=$(current_s3_note_key)
      tmp_file=$(mktemp "${WEEKNOTES_DIR}/.s3-reminder.XXXXXX")
      if ! s3_download_to_file "$key" "$tmp_file"; then
        rm -f -- "$tmp_file"
        exit 0
      fi
      file="$tmp_file"
      collect_open_todos_from_file "$file" todos
    fi
  else
    file="${WEEKNOTES_DIR}/$(current_week_file)"
    [[ ! -f "$file" ]] && exit 0
    collect_open_todos_from_file "$file" todos
  fi

  rm -f -- "$tmp_file"

  (( $(count_args "${todos[@]}") == 0 )) && exit 0

  printf 'Daily priorities (%s):\n\n' "$(date +%A)"
  local todo
  for todo in "${todos[@]}"; do
    printf '%s\n' "$todo"
  done
}

# --- Main dispatcher ---

if [[ $# -lt 1 ]]; then
  printf 'Usage: handler.sh <command> [subcommand] [args...]\n'
  printf 'Commands: todo add|list, note add, reminder, snooze, hello\n'
  exit 1
fi

cmd="$1"; shift

case "$cmd" in
  todo)
    [[ $# -lt 1 ]] && { printf 'Usage: todo add|list'; exit 1; }
    subcmd="$1"; shift
    case "$subcmd" in
      add)  cmd_todo_add "$@" ;;
      list) cmd_todo_list ;;
      *)    printf 'Unknown todo subcommand: %s' "$subcmd"; exit 1 ;;
    esac
    ;;
  note)
    [[ $# -lt 1 ]] && { printf 'Usage: note add'; exit 1; }
    subcmd="$1"; shift
    case "$subcmd" in
      add)  cmd_note_add "$@" ;;
      *)    printf 'Unknown note subcommand: %s' "$subcmd"; exit 1 ;;
    esac
    ;;
  reminder)
    cmd_reminder
    ;;
  snooze)
    cmd_snooze
    ;;
  hello)
    printf 'Hello from weeknotes-md skill!'
    ;;
  *)
    printf 'Unknown command: %s\nAvailable: todo add|list, note add, reminder, snooze, hello\n' "$cmd"
    exit 1
    ;;
esac
